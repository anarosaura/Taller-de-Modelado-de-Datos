{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://machinelearningmastery.com/wp-content/uploads/2016/03/Compare-Machine-Learning-Algorithms.png\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "- <Strong> Ana Rosaura Zamarrón Álvarez </Strong>\n",
    "- <Strong> Año </Strong>: 2021\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `ana.zamarron@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Comparación de modelos de Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que aprendimos a crear los modelos de machine learning ¿qué hacemos con ellos?\n",
    "\n",
    "Comparar varios modelos de machine learning para problemas de clasificación es necesario para poder encontrar cuál de todos los modelos es el más eficiente y tiene los resultados más precisos. \n",
    "\n",
    "Hay muchos criterios para comparar los modelos. \n",
    "\n",
    "Recordando que si la **variable de respuesta es categórica** entonces, este es un problema de **clasificación** y tenemos que usar modelos de clasificación para estimar los valores predichos. \n",
    "\n",
    "Como vimos, hay muchos modelos de clasificación candidatos. Nuestra tarea es encontrar el que sirva a nuestro propósito.\n",
    "\n",
    "Vamos a comparar los siguientes modelos:\n",
    "- Regresión logístcia\n",
    "- Árbol de decisión\n",
    "- Bosques Aleatorios\n",
    "- XGBoost\n",
    "- SVC\n",
    "- Redes Neuronales\n",
    "\n",
    "Vamos a utilizar varias métricas para comparar los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Performance (Clasificación)\n",
    "\n",
    "\n",
    "**Matriz de confusión**\n",
    "\n",
    "Las métricas de performance de evaluación se basan en el número total de las siguientes variables:\n",
    "\n",
    "- True Positives (Verdaderos positivos): Salidas predecidas correctamente como la clase positiva\n",
    "- True Negatives (Verdaderos negativos): Salidas predecidas correctamente como la clase negativa\n",
    "- False Positives (Falsos positivos): Salidas predecidas incorrectamente como la clase positiva\n",
    "- False Negatives (Falsos negativos): Salidas predecidas incorrectamente como la clase negativa\n",
    " \n",
    " Que se observa en la siguiente matriz (matriz de confusión): \n",
    " \n",
    " <img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"data:image/png;base64,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\" width=\"350px\" height=\"180px\" />\n",
    " \n",
    "Existen varias métricas de performance que se usan para evaluar qué tan efectivo es un modelo: \n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Medida de cuántas observaciones nuestro modelo predijo correctamente sobre el número total de observaciones. \n",
    "\n",
    "**Precision**\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Mide cuántas observaciones nuestro modelo predijo correctamente sobre el número de predicciones correctas e incorrectas. \n",
    "\n",
    "\n",
    "**Recall (Sensitivity)**\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Mide cuántas observaciones nuestro modelo predijo correctamente sobre el número total de observaciones. \n",
    "\n",
    "     \n",
    " **F1-Score**\n",
    " \n",
    " $$F1 Score=\\frac{2*Recall*Precision}{Recall+Precision}$$\n",
    " \n",
    " *¿Qué hace?*\n",
    "- Es un balance entre el precisión y recall\n",
    "\n",
    "**¿Cuál elegir?**\n",
    "\n",
    "- Si tenemos datos balanceados, el Accuracy podría ser la métrica más apropiada para usar. \n",
    "\n",
    "- Si estuviéramos tratando de detectar si una manzana está envenenada, el objetivo es reducir el número de Falsos Negativos, porque esperamos no equivocarnos clasificando manzanas que están envenenadas. En este caso el **Recall** sería la mejor métrica de evaluación. \n",
    "\n",
    "- Si estamos tratando de predecir si es buena idea invertir en una acción de la bolsa, esperaríamos que nuestro modelo sea bueno. EN este caso el **Precision** sería la mejor métricca de evaluación ya que mide qué tan \"correcto\" es el modelo. \n",
    "\n",
    "- Si buscamos maximizar tanto el precision como el recall, entonces el F1 Score es la mejor métrica de evaluación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los Datos\n",
    "\n",
    "Tenemos un dataset de un estudio que se le hizo a varias personas con la finalidad de identificar qué factores contribuyen a que alguien tenga una enfermedad del corazón. \n",
    "\n",
    "Se tienen las siguientes variables:\n",
    "\n",
    "- male \n",
    "- age\n",
    "- education\n",
    "- currentSmoker\n",
    "- cigsPerDay\n",
    "- BPMeds\n",
    "- prevalentStroke\n",
    "- prevalentHyp\n",
    "- diabetes\n",
    "- totChol\n",
    "- sysBP\n",
    "- diaBP\n",
    "- BMI\n",
    "- heartRate\n",
    "- glucose\n",
    "- TenYearCHD\n",
    "\n",
    "\n",
    "Basados en esas variables, queremos predecir si una persona va a tener problemas cardiovasculares en 10 años, por lo que variable a predecir es \"TenYearCHD\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargar datos\n",
    "datos = pd.read_csv('framingham.csv')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores_Nulos</th>\n",
       "      <th>Porcentaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>105</td>\n",
       "      <td>2.476415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentSmoker</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>29</td>\n",
       "      <td>0.683962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>53</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentStroke</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>50</td>\n",
       "      <td>1.179245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>19</td>\n",
       "      <td>0.448113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartRate</th>\n",
       "      <td>1</td>\n",
       "      <td>0.023585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>388</td>\n",
       "      <td>9.150943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TenYearCHD</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Valores_Nulos  Porcentaje\n",
       "male                         0    0.000000\n",
       "age                          0    0.000000\n",
       "education                  105    2.476415\n",
       "currentSmoker                0    0.000000\n",
       "cigsPerDay                  29    0.683962\n",
       "BPMeds                      53    1.250000\n",
       "prevalentStroke              0    0.000000\n",
       "prevalentHyp                 0    0.000000\n",
       "diabetes                     0    0.000000\n",
       "totChol                     50    1.179245\n",
       "sysBP                        0    0.000000\n",
       "diaBP                        0    0.000000\n",
       "BMI                         19    0.448113\n",
       "heartRate                    1    0.023585\n",
       "glucose                    388    9.150943\n",
       "TenYearCHD                   0    0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisamos si hay datos nulos\n",
    "missing = pd.DataFrame(datos.isnull().sum(),columns=['Valores_Nulos'])\n",
    "missing['Porcentaje']=missing.div(datos.shape[0])*100\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sí tenemos variables con datos nulos: glucose, BMI, totChol, BPMeds, cigsPerDay, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.429245</td>\n",
       "      <td>0.495027</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>49.580189</td>\n",
       "      <td>8.572942</td>\n",
       "      <td>32.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>4135.0</td>\n",
       "      <td>1.979444</td>\n",
       "      <td>1.019791</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentSmoker</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.494104</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigsPerDay</th>\n",
       "      <td>4211.0</td>\n",
       "      <td>9.005937</td>\n",
       "      <td>11.922462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPMeds</th>\n",
       "      <td>4187.0</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentStroke</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevalentHyp</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>0.158280</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totChol</th>\n",
       "      <td>4190.0</td>\n",
       "      <td>236.699523</td>\n",
       "      <td>44.591284</td>\n",
       "      <td>107.00</td>\n",
       "      <td>206.00</td>\n",
       "      <td>234.0</td>\n",
       "      <td>263.00</td>\n",
       "      <td>696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysBP</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>132.354599</td>\n",
       "      <td>22.033300</td>\n",
       "      <td>83.50</td>\n",
       "      <td>117.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144.00</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaBP</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>82.897759</td>\n",
       "      <td>11.910394</td>\n",
       "      <td>48.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>82.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>142.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>4221.0</td>\n",
       "      <td>25.800801</td>\n",
       "      <td>4.079840</td>\n",
       "      <td>15.54</td>\n",
       "      <td>23.07</td>\n",
       "      <td>25.4</td>\n",
       "      <td>28.04</td>\n",
       "      <td>56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartRate</th>\n",
       "      <td>4239.0</td>\n",
       "      <td>75.878981</td>\n",
       "      <td>12.025348</td>\n",
       "      <td>44.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>83.00</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>3852.0</td>\n",
       "      <td>81.963655</td>\n",
       "      <td>23.954335</td>\n",
       "      <td>40.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TenYearCHD</th>\n",
       "      <td>4240.0</td>\n",
       "      <td>0.151887</td>\n",
       "      <td>0.358953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count        mean        std     min     25%    50%     75%  \\\n",
       "male             4240.0    0.429245   0.495027    0.00    0.00    0.0    1.00   \n",
       "age              4240.0   49.580189   8.572942   32.00   42.00   49.0   56.00   \n",
       "education        4135.0    1.979444   1.019791    1.00    1.00    2.0    3.00   \n",
       "currentSmoker    4240.0    0.494104   0.500024    0.00    0.00    0.0    1.00   \n",
       "cigsPerDay       4211.0    9.005937  11.922462    0.00    0.00    0.0   20.00   \n",
       "BPMeds           4187.0    0.029615   0.169544    0.00    0.00    0.0    0.00   \n",
       "prevalentStroke  4240.0    0.005896   0.076569    0.00    0.00    0.0    0.00   \n",
       "prevalentHyp     4240.0    0.310613   0.462799    0.00    0.00    0.0    1.00   \n",
       "diabetes         4240.0    0.025708   0.158280    0.00    0.00    0.0    0.00   \n",
       "totChol          4190.0  236.699523  44.591284  107.00  206.00  234.0  263.00   \n",
       "sysBP            4240.0  132.354599  22.033300   83.50  117.00  128.0  144.00   \n",
       "diaBP            4240.0   82.897759  11.910394   48.00   75.00   82.0   90.00   \n",
       "BMI              4221.0   25.800801   4.079840   15.54   23.07   25.4   28.04   \n",
       "heartRate        4239.0   75.878981  12.025348   44.00   68.00   75.0   83.00   \n",
       "glucose          3852.0   81.963655  23.954335   40.00   71.00   78.0   87.00   \n",
       "TenYearCHD       4240.0    0.151887   0.358953    0.00    0.00    0.0    0.00   \n",
       "\n",
       "                   max  \n",
       "male               1.0  \n",
       "age               70.0  \n",
       "education          4.0  \n",
       "currentSmoker      1.0  \n",
       "cigsPerDay        70.0  \n",
       "BPMeds             1.0  \n",
       "prevalentStroke    1.0  \n",
       "prevalentHyp       1.0  \n",
       "diabetes           1.0  \n",
       "totChol          696.0  \n",
       "sysBP            295.0  \n",
       "diaBP            142.5  \n",
       "BMI               56.8  \n",
       "heartRate        143.0  \n",
       "glucose          394.0  \n",
       "TenYearCHD         1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando estadísticas básicas con los datos\n",
    "datos_stats = datos.describe()\n",
    "datos_stats = datos_stats.transpose()\n",
    "datos_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fa4b928bca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creamos gráficos básicos de los datos\n",
    "sns.pairplot(datos[['age', 'cigsPerDay', 'totChol', 'diaBP', 'BMI']], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Hombres/Mujeres')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Gráficas de algunas variables\n",
    "\n",
    "#Gráfico del género\n",
    "sns.countplot(x=datos[\"male\"]).set_title(\"Hombres/Mujeres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay más información de mujeres que de hombres en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Variable de salida por género')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable de salida por género\n",
    "sns.countplot(x=\"TenYearCHD\", hue=\"male\", data=datos).set_title('Variable de salida por género')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aún cuando hay más datos de mujeres, se observa en el gráfico de arriba qeu los hombres tienen más riesgo de desarrollar enfermedades cardiovasculares en los próximos 10 años. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cuenta de la variable de salida')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizar la variable de salida\n",
    "sns.countplot(x=datos[\"TenYearCHD\"]).set_title(\"Cuenta de la variable de salida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable de salida imbalanceada, la mayoría de las observaciones son de personas que tienen menor riesgo a desarrollar enfermedades cardiovasculares en los próximos 10 años. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitar filas con datos nulos\n",
    "datos = datos.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar X y Y\n",
    "X = datos.drop(columns='TenYearCHD', axis=0)\n",
    "y = datos['TenYearCHD']\n",
    "\n",
    "#Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cuenta de la variable de salida')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Balancear datos de salida usando algoritmo de SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "sns.countplot(x=y_train_res).set_title(\"Cuenta de la variable de salida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_res = sc.fit_transform(X_train_res)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.665\t 0.797\t 0.665\n"
     ]
    }
   ],
   "source": [
    "#Inicializar objeto\n",
    "logreg = LogisticRegression()\n",
    "#Ajustar modelo a datos de entrenamiento\n",
    "logreg.fit(X_train_res, y_train_res)\n",
    "#Predecir con datos del test\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "# Evaluacion del modelo\n",
    "accu_log = accuracy_score(y_test,y_pred_logreg)\n",
    "prec_log = precision_score(y_test,y_pred_logreg,average='weighted')\n",
    "reca_log = recall_score(y_test,y_pred_logreg,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_log,prec_log,reca_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \t Accu \t Prec \t Reca\n",
      " Eval \t 0.672 \t 0.756 \t 0.672\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(kernel='rbf')\n",
    "model_svc.fit(X_train_res, y_train_res)\n",
    "Yhat_svc = model_svc.predict(X_test)\n",
    "accu_svc = accuracy_score(y_test,Yhat_svc)\n",
    "prec_svc = precision_score(y_test,Yhat_svc,average='weighted')\n",
    "reca_svc = recall_score(y_test,Yhat_svc,average='weighted')\n",
    "print('\\n \\t Accu \\t Prec \\t Reca\\n Eval \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_svc,prec_svc,reca_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#%% Construccion y entrenamiento de la bolsa de modelos\n",
    "modelo = RandomForestClassifier(n_estimators=100,\n",
    "                               criterion='gini',\n",
    "                               max_depth=10,\n",
    "                               min_samples_split=2,\n",
    "                               min_samples_leaf=1,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=0,\n",
    "                               verbose=2)\n",
    "\n",
    "\n",
    "modelo = modelo.fit(X_train_res, y_train_res) # prediccion con la bolsa de modelos\n",
    "Yhat = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.754\t 0.756\t 0.754\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion del modelo\n",
    "accu_rf = accuracy_score(y_test,Yhat)\n",
    "prec_rf = precision_score(y_test,Yhat,average='weighted')\n",
    "reca_rf = recall_score(y_test,Yhat,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_rf,prec_rf,reca_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inicializar objeto de clasificación\n",
    "modelo_xgb = xgb.XGBClassifier(objective='binary:logistic', seed=42)\n",
    "#Entrenar modelo\n",
    "modelo_xgb.fit(X_train_res, y_train_res, verbose=False,\n",
    "          early_stopping_rounds=10, #parar de construir más árboles si no mejora la situación de los residuales\n",
    "          eval_metric='aucpr',\n",
    "          eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.768\t 0.750\t 0.768\n"
     ]
    }
   ],
   "source": [
    "Yhat_xgb = modelo_xgb.predict(X_test)\n",
    "# Evaluacion del modelo\n",
    "accu_xgb = accuracy_score(y_test,Yhat_xgb)\n",
    "prec_xgb = precision_score(y_test,Yhat_xgb,average='weighted')\n",
    "reca_xgb = recall_score(y_test,Yhat_xgb,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_xgb,prec_xgb,reca_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2926, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.5793\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5899\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.5947\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6036\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6156\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6242\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6303\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6365\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6425\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6473\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6515\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6536\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6560\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6568\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6622\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6646\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6682\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6688\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6726\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6752\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6770\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6780\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6796\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6813\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6026 - accuracy: 0.6837\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6849\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6012 - accuracy: 0.6843\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.6847\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6853\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.6861\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6865\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6863\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6857\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6865\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6871\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6857\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6871\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6863\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6871\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6861\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6871\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6885\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6879\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6885\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.6879\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6903\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6895\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6895\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6893\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6883\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6891\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6887\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6891\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6893\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6893\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6903\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6899\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6895\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6901\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6893\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6897\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6893\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.6905\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6887\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6893\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6905\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6895\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6897\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6891\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6895\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6895\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6901\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6895\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6885\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6903\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6901\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6917\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.6911\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6915\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6895\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6909\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6905\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6913\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6915\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.6901\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6911\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6911\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6915\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6917\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6909\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.6915\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6917\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6911\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.6921\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.6905\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.6921\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6921\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6923\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6937\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.6925\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6933\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6937\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6937\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6943\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6941\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6931\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6933\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.6939\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6935\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6941\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6941\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6945\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6951\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6943\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6953\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6945\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6963\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6945\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6949\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6949\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6947\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6947\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6953\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6947\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6953\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.6951\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.6955\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6949\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6961\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6957\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.6967\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.6955\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.6955\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6965\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6965\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.6971\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.6959\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.6963\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6967\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.6959\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6967\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6961\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6969\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6963\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6969\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6961\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6967\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6967\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6959\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6969\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6971\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6963\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6975\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6981\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.6975\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6973\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6975\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6963\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6973\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6983\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6971\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6975\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6981\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6987\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.6981\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.6977\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6979\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.6979\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6977\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6987\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6983\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6977\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6987\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6987\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.6989\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6993\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6991\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.6995\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6985\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.6981\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.6987\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6981\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.6987\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.6997\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6993\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.6985\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6995\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.6987\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7003\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7001\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7007\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6997\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7003\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6997\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7009\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7005\n"
     ]
    }
   ],
   "source": [
    "# Estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='tanh', input_shape=(15,))) #se puede cambiar la función de activación\n",
    "model.add(Dense(1, activation='sigmoid')) #La capa de salida debe ser sigmoidal para problemas binomiales (0 y 1)\n",
    "\n",
    "# Configuración del optimizador\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento de la red neuronal\n",
    "model_history=model.fit(X_train_res, y_train_res,epochs=200, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Accuracy function'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ver el performance del modelo en el entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Loss function')\n",
    "plt.subplot(122)\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 2ms/step - loss: 0.6099 - accuracy: 0.6626\n",
      " Test \t 0.663 \t 0.281 \t 0.656\n"
     ]
    }
   ],
   "source": [
    "#Usar el modelo para predecir\n",
    "Y_pred_NN = model.predict(X_test)\n",
    "#Evaluar modelo\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "accu_test = accuracy_score(y_test,(model.predict(X_test)>0.5).astype(\"int32\"))\n",
    "prec_test = precision_score(y_test,(model.predict(X_test)>0.5).astype(\"int32\"))\n",
    "reca_test = recall_score(y_test,(model.predict(X_test)>0.5).astype(\"int32\"))\n",
    "\n",
    "print(' Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.665301</td>\n",
       "      <td>0.797245</td>\n",
       "      <td>0.665301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.755704</td>\n",
       "      <td>0.754098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.767760</td>\n",
       "      <td>0.750084</td>\n",
       "      <td>0.767760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.662568</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  Accuracy  Precision    Recall\n",
       "0        LR  0.665301   0.797245  0.665301\n",
       "1       SVC  0.672131   0.756410  0.672131\n",
       "2        RF  0.754098   0.755704  0.754098\n",
       "3   XGBoost  0.767760   0.750084  0.767760\n",
       "4        NN  0.662568   0.280702  0.655738"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_compar_train_test = {'Modelo': ['LR', 'SVC','RF',' XGBoost', 'NN'], 'Accuracy': [accu_log, accu_svc , accu_rf, accu_xgb ,accu_test], 'Precision': [prec_log,prec_svc,prec_rf ,prec_xgb,prec_test], 'Recall': [reca_log,reca_svc,reca_rf,reca_xgb ,reca_test]} \n",
    "data_compar_train_test = pd.DataFrame(data_compar_train_test)\n",
    "data_compar_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossvalidation\n",
    "\n",
    "La idea es dividir los datos en train y test, entrenar múltiples modelos muestreando los datos de entrenamiento. \n",
    "Finalmente probar el modelo en el test set\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://miro.medium.com/max/700/1*4G__SV580CxFj78o9yUXuQ.png\" width=\"450px\" height=\"280px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar los folds que vamos a usar para todos los modelos\n",
    "n_folds = 5\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=n_folds, random_state=seed, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6811\n",
      "Precision: 0.6769\n",
      "Recall: 0.6930\n"
     ]
    }
   ],
   "source": [
    "#Inicializar modelo\n",
    "log_model=LogisticRegression(max_iter=10000)\n",
    "log_acc = cross_val_score(log_model, X_train_res, y_train_res, scoring='accuracy', cv=kfold)\n",
    "log_prec = cross_val_score(log_model, X_train_res, y_train_res, scoring='precision', cv=kfold)\n",
    "log_rec = cross_val_score(log_model, X_train_res, y_train_res, scoring='recall', cv=kfold)\n",
    "# Performance\n",
    "print('Accuracy: %.4f' % (np.mean(log_acc)))\n",
    "print('Precision: %.4f' % (np.mean(log_prec)))\n",
    "print('Recall: %.4f' % (np.mean(log_rec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 50, 'svc__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = PCA(n_components=15, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model_svc = make_pipeline(pca, svc)\n",
    "\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "\n",
    "grid = GridSearchCV(model_svc, param_grid)\n",
    "\n",
    "grid.fit(X_train_res, y_train_res)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.663\t 0.760\t 0.663\n"
     ]
    }
   ],
   "source": [
    "#Creacion de modelo con parámetros óptimos\n",
    "model_new_svc = grid.best_estimator_\n",
    "#predecir\n",
    "yfit_svc = model_new_svc.predict(X_test)\n",
    "# Evaluacion del modelo\n",
    "yhat_svc = model_new_svc.predict(X_test)\n",
    "accu_svc = accuracy_score(y_test,yhat_svc)\n",
    "prec_svc = precision_score(y_test,yhat_svc,average='weighted')\n",
    "reca_svc = recall_score(y_test,yhat_svc,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_svc,prec_svc,reca_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 3\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 5\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 7\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 9\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 11\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 1\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 5\n",
      "building tree 2 of 5\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 7\n",
      "building tree 2 of 7\n",
      "building tree 3 of 7\n",
      "building tree 4 of 7\n",
      "building tree 5 of 7\n",
      "building tree 6 of 7\n",
      "building tree 7 of 7\n",
      "building tree 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n",
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 9\n",
      "building tree 2 of 9\n",
      "building tree 3 of 9\n",
      "building tree 4 of 9\n",
      "building tree 5 of 9\n",
      "building tree 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 9\n",
      "building tree 8 of 9\n",
      "building tree 9 of 9\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 11\n",
      "building tree 2 of 11\n",
      "building tree 3 of 11\n",
      "building tree 4 of 11\n",
      "building tree 5 of 11\n",
      "building tree 6 of 11\n",
      "building tree 7 of 11\n",
      "building tree 8 of 11\n",
      "building tree 9 of 11\n",
      "building tree 10 of 11\n",
      "building tree 11 of 11\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n",
      "{'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan 0.55660576 0.56985354 0.61200429 0.65556569 0.66860682\n",
      " 0.66981406 0.67221987 0.55660576 0.56985354 0.61200429 0.65556569\n",
      " 0.66860682 0.66981406 0.67221987 0.55660576 0.56985354 0.61200429\n",
      " 0.65556569 0.66860682 0.66981406 0.67221987 0.55660576 0.56985354\n",
      " 0.61200429 0.65556569 0.66860682 0.66981406 0.67221987        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59915771 0.63608557 0.65997329 0.6750289  0.68888352 0.68627227\n",
      " 0.70654554 0.59915771 0.63608557 0.65997329 0.6750289  0.68888352\n",
      " 0.68627227 0.70654554 0.59915771 0.63608557 0.65997329 0.6750289\n",
      " 0.68888352 0.68627227 0.70654554 0.59915771 0.63608557 0.65997329\n",
      " 0.6750289  0.68888352 0.68627227 0.70654554        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.65234901\n",
      " 0.68606502 0.69951521 0.69911985 0.72481098 0.71477102 0.73002783\n",
      " 0.65234901 0.68606502 0.69951521 0.69911985 0.72481098 0.71477102\n",
      " 0.73002783 0.65234901 0.68606502 0.69951521 0.69911985 0.72481098\n",
      " 0.71477102 0.73002783 0.65234901 0.68606502 0.69951521 0.69911985\n",
      " 0.72481098 0.71477102 0.73002783        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.60819184 0.68787386\n",
      " 0.70493609 0.70854874 0.72159672 0.71918587 0.7362477  0.60819184\n",
      " 0.68787386 0.70493609 0.70854874 0.72159672 0.71717985 0.73444228\n",
      " 0.60819184 0.68787386 0.70373127 0.70734392 0.71999029 0.71617584\n",
      " 0.73122943 0.60819184 0.68988048 0.7059391  0.70774573 0.7213945\n",
      " 0.71737965 0.73163084        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.66779978 0.7221945  0.7350459\n",
      " 0.73143366 0.74367561 0.74226777 0.75732338 0.64753054 0.71477062\n",
      " 0.73022864 0.73323746 0.74628182 0.73985893 0.75772538 0.64652753\n",
      " 0.72460011 0.73082923 0.73705131 0.74066295 0.74126415 0.75672379\n",
      " 0.63268238 0.71597181 0.72922301 0.73403967 0.74166375 0.74106355\n",
      " 0.76535107        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.66760059 0.73142923 0.75652198 0.75953523\n",
      " 0.75973664 0.76254406 0.77358421 0.65375061 0.72380293 0.7557248\n",
      " 0.76033885 0.76294607 0.76033764 0.77679484 0.65716165 0.72581016\n",
      " 0.74708704 0.74668443 0.75672036 0.75471354 0.76535067 0.67081163\n",
      " 0.72098766 0.74568384 0.74588645 0.75752519 0.76234225 0.77679484\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.67623553 0.74548102 0.77659364 0.78382034 0.78382114\n",
      " 0.78241693 0.79706912 0.66660242 0.75331698 0.77298421 0.77699806\n",
      " 0.78824083 0.7876362  0.79767012 0.66981507 0.74246917 0.76776454\n",
      " 0.76776494 0.77659847 0.77940972 0.79165368 0.67904235 0.75049224\n",
      " 0.76755769 0.76876191 0.77860026 0.78542294 0.80168054        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70052527 0.76294969 0.79064966 0.79968238 0.80750746 0.8032918\n",
      " 0.81473517 0.68968492 0.75692519 0.78964383 0.79044825 0.80148296\n",
      " 0.80409199 0.81432893 0.68125662 0.76214326 0.78984524 0.79205528\n",
      " 0.80349422 0.80208557 0.81613596 0.70333027 0.75872477 0.77599384\n",
      " 0.78402074 0.79023899 0.79706509 0.80890664        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.69891462\n",
      " 0.76996914 0.78482355 0.80048539 0.80771028 0.81192292 0.82276246\n",
      " 0.70212485 0.77739443 0.80328596 0.81091749 0.82075061 0.81753675\n",
      " 0.83038553 0.69289273 0.78121151 0.7938609  0.80007976 0.8127221\n",
      " 0.81713595 0.82817589 0.69912509 0.77900529 0.79406311 0.79887695\n",
      " 0.80710364 0.81392692 0.82276105        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.69450057 0.79485827\n",
      " 0.82014981 0.82315984 0.83580601 0.83219135 0.84243131 0.71015899\n",
      " 0.78101292 0.80851108 0.8175446  0.82938716 0.8325982  0.84403814\n",
      " 0.70713909 0.78924424 0.81794701 0.82336588 0.82898555 0.83079399\n",
      " 0.84102931 0.68987605 0.76896291 0.80007956 0.81473477 0.82336568\n",
      " 0.82818053 0.83941866]\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#Inicializo modelo\n",
    "model = RandomForestClassifier(criterion='gini',\n",
    "                               min_samples_leaf=2,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=42,\n",
    "                               verbose=2)\n",
    "\n",
    "#Grid search para optimizar hiperparámetros\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid = {'max_depth': range(1, 11), #profundidad del árbol\n",
    "                                'min_samples_split': range(1, 10, 2),\n",
    "                                'n_estimators': range(1,15,2) #número de árboles\n",
    "                                }, \n",
    "                  cv=kfold,\n",
    "                  scoring='accuracy'\n",
    "                  )\n",
    "gs.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 13}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n",
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=13, random_state=42, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear modelo usando parámetros óptimos\n",
    "new_model = RandomForestClassifier(n_estimators=13,\n",
    "                               criterion='gini',\n",
    "                               max_depth=10,\n",
    "                               min_samples_split=5,\n",
    "                               min_samples_leaf=2,\n",
    "                               max_features='auto',\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=42,\n",
    "                               verbose=2)\n",
    "new_model.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.772\t 0.784\t 0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion del modelo\n",
    "yhat_rf = new_model.predict(X_test)\n",
    "accu_rf = accuracy_score(y_test,yhat_rf)\n",
    "prec_rf = precision_score(y_test,yhat_rf,average='weighted')\n",
    "reca_rf = recall_score(y_test,yhat_rf,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_rf,prec_rf,reca_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosaura/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gamma': 4,\n",
       " 'learning_rate': 0.5,\n",
       " 'max_depth': 10,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={\n",
    "    'max_depth':[5,8,10],\n",
    "    'learning_rate':[0.5,0.1,0.01],\n",
    "    'gamma':[1,4,8],\n",
    "    'reg_lambda':[0,1,10],\n",
    "    'scale_pos_weight':[1,3,5]\n",
    "}\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "                            estimator=xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='accuracy',\n",
    "                            verbose=0,\n",
    "                            n_jobs=10,\n",
    "                            cv=3)\n",
    "\n",
    "optimal_params.fit(X_train_res, y_train_res,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='aucpr',\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  verbose=False)\n",
    "optimal_params.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=0.9, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construir y evaluar el XGBoost con los hiperparámetros óptimos\n",
    "modelo_xgb = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42,\n",
    "                           gamma=1,\n",
    "                           learning_rate=0.01,\n",
    "                           max_depth=10,\n",
    "                           reg_lambda=1,\n",
    "                           scale_pos_weight=1,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5)\n",
    "\n",
    "modelo_xgb.fit(X_train_res, y_train_res,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_metric='aucpr',\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.786\t 0.754\t 0.786\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion del modelo\n",
    "yhat_xgb = modelo_xgb.predict(X_test)\n",
    "accu_xgb = accuracy_score(y_test,yhat_xgb)\n",
    "prec_xgb = precision_score(y_test,yhat_xgb,average='weighted')\n",
    "reca_xgb = recall_score(y_test,yhat_xgb,average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_xgb,prec_xgb,reca_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 3ms/step - loss: 0.6806 - accuracy: 0.5624\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7680\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.8382\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8491\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8507\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8503\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8499\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8499\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8499\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.85 - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8499\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8503\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8503\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8503\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8503\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8507\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8511\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8507\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8507\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8511\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8511\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8515\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8515\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8519\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8515\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8515\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8519\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8519: 0s - loss: 0.3705 - accuracy: 0.\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8523\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8531\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8527\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8527\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8523\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8535\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8531\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8539\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8539\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8539\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8539\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8539\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8539\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8539\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8539\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8539\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8543\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8551\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8559\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8559\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8563\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8567\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8567\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8563\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8571\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8571\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8579\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8583\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8583\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8587\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8587\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8599\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8603\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8607\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8607\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8607\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8607\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8615\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8619\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8611\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8619\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8623\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8619\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8627\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8627\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8623\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8627\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8635\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8623\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8631\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8647\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8647\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8643\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8647\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8651\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8643\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8643\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8647\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8639\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8651\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8647\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8651\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8655\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8647\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8655\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8655\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8655\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8659\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8663\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8663\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8659\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8663\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8667\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8663\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8667\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8663\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8667\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8663\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8663\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8667\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8675\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8671\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8675\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8675\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8679\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8691\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8691\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8695\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8691\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8695\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8703\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8703\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8699\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8703\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8703\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8703\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8703\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8707\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8699\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8699\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8699\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8707\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8703\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8711\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8707\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8715\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8715\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8707\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8703\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8711\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8711\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8715\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8707\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8703\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8711\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8699\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8699\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8703\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8699\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8703\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8695\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8707\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8703\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8715\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8703\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8703\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8703\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8707\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8707\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8707\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8719\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8715\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8715\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8719\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8719\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8715\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8711\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8727\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8723\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8723\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8723\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8727\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8715\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8723\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8723\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8719\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8723\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8727\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8727\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8727\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8723\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8719\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8719\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8723\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8719\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8719\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8723\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8719\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8723\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8719\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8719\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8723\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8723\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8719\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8719\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8719\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8727\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8723\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8727\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8727\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8727\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8727\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8727\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5697\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7788\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8189\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8338\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8438\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8466\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8503\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8519\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8527\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8523\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8527\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8523\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8507\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8507\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8507\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8507\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8507\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8515\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8495\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8499\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8515\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8503\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8503\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8495\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8499\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8495\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8499\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8499\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8507\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8511\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8507\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8511\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8507\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8511\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8507\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8519\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8515\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8519\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8511\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8511\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8507\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8503\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8511\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8507\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8511\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8507\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8507\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8503\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8507\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8503\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8499\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8503\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8503\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8503\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8511\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8515\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8507\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8519\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8515\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8515\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8519\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8519\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8523\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8523\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8519\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8523\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8519\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8519\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8519\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8519\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8519\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8523\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8519\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8519\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8519\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8519\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8523\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8523\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8527\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8535\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8523\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8531\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8535\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8535\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8539\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8539\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8539\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8543\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8531\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8539\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8539\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8535\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8547\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8535\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8543\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8543\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8543\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8547\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8543\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8543\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8543\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8543\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8539\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8547\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8539\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8531\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8547\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8539\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8543\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8539\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8539\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8543\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8543\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8547\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8547\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8543\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8543\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8535\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8539\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8543\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8539\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8539\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8539\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8535\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8543\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8539\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8535\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8539\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8543\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8535\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8535\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8539\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8539\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8531\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8539\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8539\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8535\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8539\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8547\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8547\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8543\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8547\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8547\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8547\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8551\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8543\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8555\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8547\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8551\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8551\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8547\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8547\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8539\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8539\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8539\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8551\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8555\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8539\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8539\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8547\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8539\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8543\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8547\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8551\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8543\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8539\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8539\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8543\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8547\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8539\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8539\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8547\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8547\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8547\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8543\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8543\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8543\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8539\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8531\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8543\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8531\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8551\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8543\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8543\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8543\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8539\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8539\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8543\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8547\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8531\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8539\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8539\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8535\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8547\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8539\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8535\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8531\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8531\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8535\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8543\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.7615 - accuracy: 0.4946\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7463\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8350\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8470\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8495\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8507\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8511\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8511\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8511\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8519\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8523\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8523\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8535\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8535\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8535\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8547\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8555\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8563\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8575\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8583\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8575\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8575\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8599\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8595\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8595\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8599\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8607\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8607\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8607\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8615\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8611\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8627\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8611\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8623\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8623\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8627\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8627\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8623\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8631\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8623\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8635\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8635\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8631\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8635\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8631\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8631\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8635\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8635\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8631\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8643\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8647\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8651\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8651\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8639\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8651\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8647\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8643\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8663\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8651\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8659\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8655\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8655\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8659\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8663\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8667\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8647\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8651\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8659\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8655\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8659\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8663\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8667\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8663\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8667\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8659\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8667\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8655\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8663\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8667\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8667\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8655\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8663\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8659\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8655\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8655\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8663\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8655\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8659\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8655\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8655\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8659\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8651\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8655\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8655\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8651\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8651\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8651\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8647\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8651\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8655\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8647\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8655\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8651\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8647\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8655\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8647\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8651\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8651\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8655\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8651\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8655\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8647\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8651\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8667\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8659\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8663\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8659\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8663\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8655\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8663\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8667\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8655\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8663\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8663\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8663\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8671\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8671\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8671\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8667\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8667\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8671\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8671\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8667\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8671\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8675\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8675\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8663\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8683\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8679\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8671\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8675\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8675\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8679\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8687\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8671\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8675\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8687\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8679\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8683\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8679\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8683\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8691\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8675\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8687\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8679\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8691\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8687\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8687\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8691\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8699\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8695\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8691\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8695\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8699\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8695\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8703\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8691\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8707\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8699\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8699\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8711\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8715\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8715\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8711\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8711\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8711\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8715\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8707\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8719\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8723\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8707\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8719\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8723\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8723\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8723\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8727\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8727\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8735\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8723\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8752\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8731\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8747\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8747\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8743\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8747\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8739\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8743\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8747\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8743\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8743\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6811 - accuracy: 0.5982\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7278\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7804\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8173\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8350\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8414\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8442\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8483\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8503\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8495\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8511\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8511\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8511\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8511\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8511\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8511\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8511\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8519\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8511\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8511\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8511\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8499\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8499\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8499\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8499\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8499\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8499\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8499\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8495\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8495\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8499\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8495\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8487\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8491\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8491\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8495\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8491\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8499\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8499\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8507\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8503\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8503\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8499\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8507\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8503\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8515\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8503\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8511\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8503\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8503\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8503: 0s - loss: 0.3791 - accura\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8503\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8503\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8507\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8503\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8499\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8503\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8503\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8503\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8499\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8507\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8503\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8511\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8503\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8507\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8499\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8499\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8511\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8503\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8507\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8511\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8503\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8511\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8515\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8511\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8507\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8511\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8511\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8519\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8515\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8527\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8523\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8519\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8527\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8523\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8527\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8527\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8531\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8523\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8535\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8531\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8523\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8539\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8539\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8539\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8539\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8539\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8535\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8543\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8543\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8543\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8543\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8543\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8547\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8543\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8543\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8543\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8539\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8543\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8543\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8551\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8551\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8547\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8555\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8547\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8555\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8551\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8555\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8555\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8551\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8555\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8555\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8555\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8551\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8559\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8539\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8551\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8551\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8555\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8551\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8547\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8543\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8543\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8547\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8543\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8551\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8551\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8543\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8551\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8551\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8551\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8547\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8559\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8543\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8551\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8551\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8551\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8555\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8555\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8559\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8559\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8555\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8563\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8555\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8547\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8563\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8563\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8563\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8567\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8555\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8555\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8567\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8563\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8563\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8567\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8563\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8571\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8559\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8559\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8567\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8559\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8567\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8563\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8571\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8559\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8575\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8567\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8555\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8567\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8571\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8559\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8571\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8571\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8575\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8571\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8575\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8571\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8567\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8571\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8571\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8579\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8571\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8567\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8583\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3647 - accuracy: 0.8575\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3647 - accuracy: 0.8571\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8567: 0s - loss: 0.3801 - accuracy: 0.84 - ETA: 0s - loss: 0.3666 - accuracy: \n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8579\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 2s 2ms/step - loss: 0.7248 - accuracy: 0.5488\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7358\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8198\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8450\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8531\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8571\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8551\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8567\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8575\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8571\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8575\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8587\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8579\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8587\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8587\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8591\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8587\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8603\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8599\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8599\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8599\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8595\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8603\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8611\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8619\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8619\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8615\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8623\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8627\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8623\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8623\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8623\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8627\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8639\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8643\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8643\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8639\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8639\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8647\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8647\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8647\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8651\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8659\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3540 - accuracy: 0.8655\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3537 - accuracy: 0.8651\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3533 - accuracy: 0.8659\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8655\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8659\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8651\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8663\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8663\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8663\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8667\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8671\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8675\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8675\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8671\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8679\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8679\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8679\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8675\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8679\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8675\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8679\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8687\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8679\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8683\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8683\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8683\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8667\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8683\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8679\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8679\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8671\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8675\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8683\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8675\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8675\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8675\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8675\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8683\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8679\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8675\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8671\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8675\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8675\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8679\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8679\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8687\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8687\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8687\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8691\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8699\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8695\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8691\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8695\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8687\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8695\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8699\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8691\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8707\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8695\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8695\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8695\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8683\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8695\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8695\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8695\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8703\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8703\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8699\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8699\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8687\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8695\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8699\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8699\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8699\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8695\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8695\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8695\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8695\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8691\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8699\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8695\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8695\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8695\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8707\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8695\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8707\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8711\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8707\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8707\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8715\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8711\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8711\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8707\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8715\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8711\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8711\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8719\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8719\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8707\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8711\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8719\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8707\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8715\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8711\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8719\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8723\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8719\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8723\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8715\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8723\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8727\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8723\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8727\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8727\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8719\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8727\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8727\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8731\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8723\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8731\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8731\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8731\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8731\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8735\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8739\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8739\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8731\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8743\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8743\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8735\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8747\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8747\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8747\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8747\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8747\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8752\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8756\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8752\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8756\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8747\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8752\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8760\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8752\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8756\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8760\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8756\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8756\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8760\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8760\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8760\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8768\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8772\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8768\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8772\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8768\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8776\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8780\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.7641 - accuracy: 0.4621\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7619\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.8358\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8426\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8442\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8446\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8454\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8450\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8466\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8470\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8483\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8479\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8475\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8475\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8487\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8479\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8491\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8491\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8495\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8491\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8491\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8487\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8483\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8491\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8499\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8487\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8495\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8499\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8503\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8503\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8507\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8511\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8511\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8499\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8511\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8503\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8511\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8511\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8519\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8515: 0s - loss: 0.3418 - accuracy: \n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8523\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8519\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8519\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8527\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8531\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8531\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8523\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8523\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8527\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8531\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8527\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8527\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8527\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8531\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8527\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8527\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8531\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8527\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8527\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8527\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8527\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8523\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8523\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8523\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8527\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8531\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8523\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8531\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8531\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8527\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8527\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8527\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8531\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8527\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8523\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8519\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8523\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8523\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8527\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8527\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8531\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8535\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8535\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8527\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8523\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8531\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8535\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8535\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8535\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8535\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8535\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8535\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8535\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8531\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8535\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8531\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8531\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8535\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8535\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8535\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8531\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8527\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8531\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8535\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8531\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8527\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8535\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8531\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8531\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8539\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8535\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8531\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8531\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8531\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8531\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8527\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8531\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8531\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8531\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8535: 0s - loss: 0.3700 - accuracy\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8535\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8535\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8539\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8543\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8539\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8543\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8539\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8539\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8543\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8543\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8547\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8551\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8555\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8555\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8551\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8559\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8563\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8559\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8559\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8563\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8559\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8559\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8559\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8567\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8563\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8559\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8567\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8563\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8559\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8551\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.85 - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8563\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8559\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8563\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8559\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8563\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8559\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8559\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8559\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8559\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8559\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8559\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.8559\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8555\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8555\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8559\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8571\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8559\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8555\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8559\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8555\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8563\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8559\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8555\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8559\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8559\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8559\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8559\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8551\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8559\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8555\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8563\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8555\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8555\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8551\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8555\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8547\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8555\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8551\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8551\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8551\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8547\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8555\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8555\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8551\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8551\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 3ms/step - loss: 0.6877 - accuracy: 0.5632\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7001\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7852\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.8274\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8390\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8446\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8491\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8511\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8519\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8519\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8523\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8519\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8515\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8523\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8531\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8523\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8523\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8523\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8531\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8527\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8535\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8535\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8539\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8543\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8543\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8551\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8563\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8571\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8583\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8583\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8595: 0s - loss: 0.3580 - accuracy: 0.85\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8611\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8611\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8623\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8619: 0s - loss: 0.3724 - accuracy\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8623\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8619\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8623\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8631\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8639\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8643\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8639\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8643\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8647\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8631\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8639\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8639\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8639\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8639\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8635\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8643\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8639\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8639\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8659\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8663: 0s - loss: 0.3507 - accura\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8651\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8667\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8659\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8675\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8675\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8659\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8667\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8663\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8659\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8659\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8655\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8671\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8667\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8663\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8663: 0s - loss: 0.3410 - accuracy: 0.\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8667\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8671\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8659\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8667\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8655\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8655\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8651\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8655\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8659\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8655\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8655\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8659\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8655\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8655\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8643\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8647\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8643\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8643\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8651\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8651\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8651\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8651\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3402 - accuracy: 0.8643\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8659\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8647\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8647\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8651\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8651\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8635\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8639\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8639\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8655\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8655\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8647\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8643\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8647\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8647\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8655\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8651\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8651\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8655\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8659\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8651\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8663\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8663\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8667\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8667\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8663\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8667\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8663\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8659\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8663\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8663\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8671\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8663\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8659\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8663\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8663\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8667\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8671\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8663\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8663\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8659\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8663\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8667\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8655\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8671\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8675\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8659\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8671\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8671\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8671\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8667\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8671\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8663\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8667\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8667\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8675\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8675\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8667\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8663\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8675\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8679\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8687\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8683\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8679\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8683\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8675\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8683\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8679\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8687\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8691\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8691\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8691\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8687\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8679\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8691\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8687\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8683\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8683\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8687\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8683\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8683\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8683\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8683\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8683\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8683\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8687\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8679\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8683\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8683\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8679: 0s - loss: 0.3347 - accuracy: 0.86\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8691\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8687\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8679\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8683\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8679\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8679\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8683\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8683\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8687\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8679\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8691\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8687\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8683\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8679\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8687\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8687\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8691\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8691\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6504 - accuracy: 0.6415\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7656\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8149\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8258\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8362\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8390\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8430\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8434\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8454\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8442\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8446\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8434\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8442\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8434\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8442\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8438\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8458\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8454\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8454\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8458\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8466\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8470\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8479\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8491\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8503\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8511\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8507\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8527\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8519\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8523\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8523\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8535\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8527\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8527\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8523\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8531\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8523\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8527\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8527\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8527\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8527\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8531\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8535\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8531\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8531\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8539\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8539\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8543\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8559\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8551\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8551\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8551\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8555\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8551\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8551\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8551\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8555\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8555\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8559\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8559\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8567\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8563\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8559\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8567\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8567\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8571\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8567\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8567\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8563\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8567\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8563\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8563\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8571\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8575\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8575\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8579\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8575\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8579\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8575\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8571\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8579\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8579\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8579\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8579\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8575\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8579\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8579\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8579\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8579\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8579\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8579\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8579\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8583\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8575\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8579\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8579\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8575\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8579\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8583\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8579\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8579\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8575\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8579\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8583\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8575\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8579\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8587\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8587\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8579\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8595\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8583\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8583\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8583\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8583\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8579\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8587\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8583\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8587\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8595\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8591\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8587\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8595\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8599\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8595\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8591\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8599\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8595\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8595\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8599\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8591\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8595\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8599\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8599\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8595\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8595\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8595\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8599\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8595\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8595\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8595\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8599: 0s - loss: 0.3636 - accuracy: 0.86\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8595\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8599\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8599\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8599\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8599\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8603\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8595\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8595\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8591\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8591\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8595\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8591\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8591\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8595\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8595\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8591\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8591\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8599\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8583\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8587\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8591\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8587\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8587\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8587\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8587\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8591\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8591\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8591\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8583\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8587\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8583\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8587\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8583\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8579\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8583\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8587\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8583\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8583\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8583\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8583\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8579\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8583\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8583\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8591\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8583\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8583\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8583\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8583\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8583\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8583\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8583\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8587\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8579\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8579\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8583\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8583\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8583\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8583\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8583\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6657 - accuracy: 0.6006\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7391\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8025\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8306\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8426\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8462\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8495\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8495\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8495\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8499\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8499\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8507\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8499\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8495\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8499\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8491\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8499\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8495\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8503\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8511\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8519\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8527\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8527\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8539\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8543\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8539\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8551\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8555\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8551\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8551\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8551\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8547\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8555\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8555\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8559\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8563\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8567\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8563\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8567\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8567\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8571\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8575\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8579\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8583\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8587\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8587\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8591\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8591\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8591\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8587\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8587\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8591\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8595\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8591\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8591\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8591\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8595\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8599\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8595\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8599\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8611\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8619\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8619\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8619\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8619\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8615\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8623\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8623\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8627\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8631\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8627\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8631\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8635\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8627\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8631\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8627\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8631\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8635\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8635: 0s - loss: 0.3616 - accuracy: \n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8639\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8639\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8639\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8639\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8639\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8635\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8643\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8639\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8635\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8639\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8647\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8639\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8647\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8643\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8647\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8651\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8651\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8647\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8651\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8651\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8651\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8655\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8651\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8643\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8651\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8647\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8647\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8651\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8647\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8651\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8647\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8647\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8651\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8655\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8647\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8655\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8655\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8651\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8663\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8655\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8663\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8671\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8659\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8671\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8651\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8667\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8663\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8671\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8659\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8663\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8671\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8675\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8675\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8687\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8679\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8671\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8683\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8667\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8671\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8671\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8683\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8691\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8679\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8687\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8691\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8703\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8691\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8691\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8691\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8691\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8695\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8699\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8691\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8703\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8695\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8703\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8719\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8703\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8703\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8703\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8707\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8707\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8711\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8715\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8703\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8719\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8711\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8703\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8723\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8711\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8719\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8707\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8715\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8703\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8707\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8707\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8707\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8703\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8711\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8707\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8715\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8719\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8707\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8715\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8719\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8719\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8715\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8711\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8723\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8727\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8723\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8719\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8727\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8715\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8719\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8735\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8719\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8735\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8727\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8731\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8723\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6494 - accuracy: 0.6471\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7222\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7736\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7997\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8165\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8270\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8334\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8406\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8406\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8446\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3922 - accuracy: 0.8450\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8458\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8454\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8462\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8446\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8462\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8479\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8495\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8499\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8495\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8499\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8503\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8511\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8519\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8519\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8523: 0s - loss: 0.3803 - accuracy: 0.\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8523\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8527\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8535\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8531\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8535\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8531\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8527\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8535\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8527\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8527\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8527\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8527\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8523\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8527\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8527\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8519\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8523\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8523\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8527\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8523\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8531\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8523\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8519\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8523\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8515\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8515\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8511\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8523\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8527\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8519\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8515\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8515\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8515\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8515\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 6ms/step - loss: 0.3724 - accuracy: 0.8515\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3723 - accuracy: 0.8515: 0s - loss: 0.3722 - accuracy: 0.\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8523\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8527\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8527\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8523\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8527\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8531\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8527\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8523\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8527\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8531\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8539\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8531\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8535\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8539\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8539\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8535\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8539\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8543\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8539\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8539\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8539\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8543\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8531\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8543\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8543\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8543\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8551\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8543\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8547\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8547\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8543\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8547\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8539\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8543\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8543\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8547: 0s - loss: 0.3520 - accuracy: 0.\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8547\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8543\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8551\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8551\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8547\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8551\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8551\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8555\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8551\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8555\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8559\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8555\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8551\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8551\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8551\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8555\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8555\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8555\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8551\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8559\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8559\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8555\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8551\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8551\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8555\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8555\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8567\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8555\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8567\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8559\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8567\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8563\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8567\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8571\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8563\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8567\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8571\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8571\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8575\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8571\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8567\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8567\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8567\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8567\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8571\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8575\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8583\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8571\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8575\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8579\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8567\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8579\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8571\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8575\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8567\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8571\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8575\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8575\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8571\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8571\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8575\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8567\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8571\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8571\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8571\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8571\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8571\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8563\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8575\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8567\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8575\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8571\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8575\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8579\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8571\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8575\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8575\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8579\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8579\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8583\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8567\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8579\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8575\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8579\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8571\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8579\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8587\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8579\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8579\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8583\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8583\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8575\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8583\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8583\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8583\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8583\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8587\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8583\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8579\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8583\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.7102\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7828\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8250\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8470\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8491\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8547\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8539\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8551\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8559\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8563\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8579\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8591\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8587\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8595\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8591\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8591\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8595\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8599\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8599\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8611\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8603\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8607\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8611\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8611\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8615\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8603\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8611\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8611\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8611\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8615\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8619\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8631\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8631\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8639\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8631\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8639\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8639\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8631\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8639\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8627\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8627\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8631\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8627\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8635\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8635\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8635\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8635\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8635\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8635\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8643\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8635\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8643\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8639\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8643\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8631\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8651\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8639\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8647\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8643\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8647\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8647\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8647\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8643\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8651\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8651\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8651\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8651\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8647\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8647\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8655\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8659\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8651\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8659\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8667\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8659\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8659\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8667\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8671\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8667\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8675\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8679\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8679\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8687\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8683\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8683\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8683\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8683\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8691\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8683\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8691\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8691\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8695\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8695\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8691\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8695\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8695\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8687\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8691\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8695\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8691\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8687\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8691\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8687\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8691\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8675\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8687\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8683\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8675\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8691\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8679\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8695\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8695\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8703\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8695\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8691\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8687\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8703\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8691\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8695\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8695\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8699\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8695\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8699\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8691\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8699\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8699\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8691\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8683\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8691\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8691\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8683\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8691\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8691\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8691\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8691\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8691\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8691\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8699\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8691\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8691\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8687\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8691\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8699\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8699\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8699\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8691\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8699\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8699\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8703\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8699\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8699\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8703\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8707\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8703\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8707\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8699\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8711\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8715\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8707\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8707\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8711\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8715\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8707\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8707\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8711\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8715\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8719\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8703\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8707\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8723\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8727\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8731\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8719\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8719\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8719\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8727\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8727\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8719\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8731\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8731\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8719\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8731\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8735\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8731\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8743\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8731\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8735\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8735\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8731\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8735\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8735\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8739\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8743\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8735\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8735\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8739\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8739\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8739\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8735\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8739\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.6776\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7965\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8258\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8410\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8462\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8483\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8519\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8523\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8535\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8527\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8527\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8527\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8519\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8531\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8527\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8531\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8535\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8531\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8531\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8535\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8531\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8535\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8527\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8531\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8531\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8539\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8539\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8531\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8543\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8543\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8543\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8551\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8547\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8551\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8555\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8555\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8555\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8555\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8551\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8551\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8547\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8551\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8559\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8551\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8543\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8551\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8555\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8555\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8551\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8559\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8559\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8547\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8551\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8547\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8555\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8547\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8555\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8551\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8555\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8555\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8551\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8559\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8551\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8551\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8551\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8559\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8555\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8559\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8551\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8547\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8559\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8555\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8555\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8555\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8547\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8551\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8551\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8551\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8555\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8555\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8563\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8551\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8559\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8547\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8567\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8559\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8567\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8559\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8567\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8559\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8567\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8567\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8559\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8567\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8559\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8563\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8567\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8571\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8575\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8575\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8579\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8571\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8579\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8579\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8571\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8575\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8571\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8583\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8571\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8579\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8579\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8571\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8579\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8579\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8579: 0s - loss: 0.3698 - accuracy: 0.85\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8575\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8571\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8571\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8583\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8575\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8571\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8583\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8583\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8575\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8571\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8571\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8567\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8579\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8579\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8579\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8575\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8575\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8567\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8575\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8575\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8579\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8571\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8579\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8571\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8575\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8575\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8579\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8571\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8567\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8571\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8579\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8563\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8571\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8571\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8571\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8583\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8571\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8571\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8571\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8571\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8575\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8571\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8563\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8575\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8575\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8563\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8575\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8575\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8567\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8563\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8567\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8567\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8555: 0s - loss: 0.3516 - accuracy: 0.\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8575\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8571\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8567\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8575\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8567\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8567\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8567\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8575\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8567\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8567\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3634 - accuracy: 0.8575\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8571\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8567\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8567\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8567\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8571\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8567\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8575\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8563\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8563\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8563\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8559\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.8563\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8563\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8563\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8567\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8567\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8571\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8559\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8571\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.6624\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8073\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.8470\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8519\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8531\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8519\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8531\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8547\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8551\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8547\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8547\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8543\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8551\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8555\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8567\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8571\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8583\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8587\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8603\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8599\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8603\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8607\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8595\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8595\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8607\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8603\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8615\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8619\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8619\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8627\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8639\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8639\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8647\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8655\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 1s 6ms/step - loss: 0.3528 - accuracy: 0.8651\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8651\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8659\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8651\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8663\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3511 - accuracy: 0.8667\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3508 - accuracy: 0.8663\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8671\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8675\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8683\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8679\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8683\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8683\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8683\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8687\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8695\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8699\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8699\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8719\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8703\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8703: 0s - loss: 0.3197 - accuracy: 0.\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8707\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8715\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8719\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8707\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8711\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8719\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8707\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8711\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8711\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8707\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8719\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8727\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8723\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8727\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8727\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8719\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8719\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8723\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8723\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8731\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8731\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8735\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8743\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8747\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8739\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8743\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8752\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8739\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8752\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8760\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8743\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8747\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8747\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8747\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8739\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8743\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8756\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8747\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8747\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8752\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8747\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8752\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8747\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8743\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8760\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8756\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8752\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8764\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8760\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8760\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8764\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8760\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8760\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8764\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8760\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8756\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8764\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8764\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8764\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8760\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8768\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8760\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8776\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8768\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8768\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8768\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8764\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8764\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8772\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8768\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8776\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8772\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8788\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8768\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8776\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8784\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8764\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8764: 0s - loss: 0.3511 - accuracy\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8776\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8768\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.8772\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8780\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8776\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8780\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8780\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8792\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8780\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8768\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8792\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8780\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8796\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8788\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8796\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8796\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8808\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8800\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8804\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8804\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8804\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8808\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8808\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8824\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8804\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8816\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8816\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8816\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8824\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8820\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8820\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8812\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8824\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8824\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8812\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8832\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8836\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8844\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8820\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8824\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8828\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8828\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8836\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8832\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8844\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8844\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8848\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8852\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8856\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8876\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8848\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8856\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8864\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8860\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8848\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8864\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8856\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8852\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8856\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8856\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8860\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8852\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8860\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8860\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8856\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6966 - accuracy: 0.5781\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7375\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8061\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8298\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8386\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8446\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8475\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8503\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8503\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8511\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8511\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8519\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8515\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8511\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8503\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8507\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8499\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8503\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8515\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8511\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8511\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8515\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8519\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8519\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8523\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8527\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8527\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8531\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8535\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8531\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8531\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8535\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8535\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8535\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8539\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8539\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8539\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8543\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8547\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8547\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8543\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8543\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8555\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8547\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8547\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8551\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8547\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8547\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8547\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8547\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8547\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8547\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8543\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8543\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8555\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8555\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8563\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8571\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8567\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8563\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8563\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8571\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8571\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8571\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8571\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8567\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8575\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8575\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8571\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8571\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8571\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8575\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8575\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8571\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8575\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8575\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8575\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8575\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8587\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8579\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8583\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8595\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8587\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8587\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8595\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8587\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8591\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8599\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8595\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8595\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8595\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8599\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8599\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8595\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8599\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8587\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8595\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8599\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8595\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8599\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8595\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8595\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8595\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8595\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8595\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8595\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8599\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8595\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8595\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8595\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8603\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8591\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8599\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8595\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8595\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8595\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8595\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8591\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8595\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8591\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8595\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8595\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8599\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8599\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8607\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8603\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8603\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8607\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8603\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8603\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8603\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8603\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8603\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8603\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8607\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8603: 0s - loss: 0.3523 - accuracy: 0.\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8603\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8611\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8607\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8603\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8607\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8607\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8611\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8607\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8611\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8619\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8611\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8611\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8615\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8607\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8615\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8611\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8615\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8611\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8611\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8615\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8619\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8619\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8615\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8611\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8615\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8615\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8619\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8615\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8611\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8623\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8619\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8615\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8623\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8623\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8627\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8619\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8623\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8623\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8615\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8623\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8615\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8619\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8627\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8631\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8631\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8619\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8627\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8631\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8619\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8627\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8627\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8631\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8627\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8627\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8639\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8631\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8635\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8631\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8639\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8639\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8635\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8639\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8623\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8631\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.7284 - accuracy: 0.5588\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7254\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8105\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8422\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8499\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8511\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8511\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8507\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8515\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8515\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8515\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8519\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8523\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8527\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8523\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8507\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8507\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8519\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8527\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8519\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8515\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8519\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8531\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8527\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8535\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8535\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8551\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8543\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8567\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8567\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8567\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8571\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8579\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8583\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8587\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8583\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8587\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8591: 0s - loss: 0.3724 - accuracy: \n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8591\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8615\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8607\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8611\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8619\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8619\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8619\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8619\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8623\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8619\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8619\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8619\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8627\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8631\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8647\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8639\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8643\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8635\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8643\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8655\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8651\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8655\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8655\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8659\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8647\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8651\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8651\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8659\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8651\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8651\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8659\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8655\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8655\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8671\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8659\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8659\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8659\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8663\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8663\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8663\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8663\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8663\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8663\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8667\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8667\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8671\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8659\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8671\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8671\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8675\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8675\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8671\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8663\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8659\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8675\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8671\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8667\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8667\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8663\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8667\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8671\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8671\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8671\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8667\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8667\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8667\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8667\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8671\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8667\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8675\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8671\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8675\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8687\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8691\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8695\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8691\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8703\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8687\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8691\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8695\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8695\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8707\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8695\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8703\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8703\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8695\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8699\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8703\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8711\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8703\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8703\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8715\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8703\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8707\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8703\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8699\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8707\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8711\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8707\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8711\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8707\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8727\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8723\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8715\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8719\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8723\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8723\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8731\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8723\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8723\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8723\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8727\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8731\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8739\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8735\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8727\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8727\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8727\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8719\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8723\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8723\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8723\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8723\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8731\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8735\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8727\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8731\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8723\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8731\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8735\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8731\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8743\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8731\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8731\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8743\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8735\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8743\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8743\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8743\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8735\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8735\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8743\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8739\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8739\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8747\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8743\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8747\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8739\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8752\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8747\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8743\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8735\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8743\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8747\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8756\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8747\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8764\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8760\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8752\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8768\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8764\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8760\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.7637 - accuracy: 0.4821\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7081\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8153\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8414\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8475\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8475\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8495\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8499\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8499\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8495\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8499\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8491\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8495\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8499\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8499\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8503\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8507\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8511\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8507\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8511\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8515\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8519\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8519\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8527\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8527\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8535\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8531\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8539\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8539\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8531\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8531\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8535\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8535\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8531\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8527\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8531\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8535\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8531\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8531\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8535\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8535\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8543\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8539\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8543\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8535\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8539\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8543\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8543\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8539\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8539\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8543\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8539\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8535\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8539\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8543\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8539\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8539\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8535\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8543\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8543\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8543\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8547\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8543\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8543\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8551\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8551: 0s - loss: 0.3721 - accuracy\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8547\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8543\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8551\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8539\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8547\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8543\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8547\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8543\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8547\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8547\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8547\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8547\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8547\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8551\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8547\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8547\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8551\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8551\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8555\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8555\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8547\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8547\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8547\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8551\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8551\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8551\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8551\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8559\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8551\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8551\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8551\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8563\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8555\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8555\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8555\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8555\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8555\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8551\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8559\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8551\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8555\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8555\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8551\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8555\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8551\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8555\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8555\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8555\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8555\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8547\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8559\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8547\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8551\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8555\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8547\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8547\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8547\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8555\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8547\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8543\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8543\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8543\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8547\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8543\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8547\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8551\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8543\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8547\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8547\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8547\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8547\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8551\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8543\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8543\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8539\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8547\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8551\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8547\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8543\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8539\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8547\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8547\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8547\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8543\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8543\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8547\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8543\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8547\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8547\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8539\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8539\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8547\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8547\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8539\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8543\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8547\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8539\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8547\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8547\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8547\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8539\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8543\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8539\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8543\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8547\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8547\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8547\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8547\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8551\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8543\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8547\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8543\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8543\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8543\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8543\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8543\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8547\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8547\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8543\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8543\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8547\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8543\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8539\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8551\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8547\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8555\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8555\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8551\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8555\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8551\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8555\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8555\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6678 - accuracy: 0.6230\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7342\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7957\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8306\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8426\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8551\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8575\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8575\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8579\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8587\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8567\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8563\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8567\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8559\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8563\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8563\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8563\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8571\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8571\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8563\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8563\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8563\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8571\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8579\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8587\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8595\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8587\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8599\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8599\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8599\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8603\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8619\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8619\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8623\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8623\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8631\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8631\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8631\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8631\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8635\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8643\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8643\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8647\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8647\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8651\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8651\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8647\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8655\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8655\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8667\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8667\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8659\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8663\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8667\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8667\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8675\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8675\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8683\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8687\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8679\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8687\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8683\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8687\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8687\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8691\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8699\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8707\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8691\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8703\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8703\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8715\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8707\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8707\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8707\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8711\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8711\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8711\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8711\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8711\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8711\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8715\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8711\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8715\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8715\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8715\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8699\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8707\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8699\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8695\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8695\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8691\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8695\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8695\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8675\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8695\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8687\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8683\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8687\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8683\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8691\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8687\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8691\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8683\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8687\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8687\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8683\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8683\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8699\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8683\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8687\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8687\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8699\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8695\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8695\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8699\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8699\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8703\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8695\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8691\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8707\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8703\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8703\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8707\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8707\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8703\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8703\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8703\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8707\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8703\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8707\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8711\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8715\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8711\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8711\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8707\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8711\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8711\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8715\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8711\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8707\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8711\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8715\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8711\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8715\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8727\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8699\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8723\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8711\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8715\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8719\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8723\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8711\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8723\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8739\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8731\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8723\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8727\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8735\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8731\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8735\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8743\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8756\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8752\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8752\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8752\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8756\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8756\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8752\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8756\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8752\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8768\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8764\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8764\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8756\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8764\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8772\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8768\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8772\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8780\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8776\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8772\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8772\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8780\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8780\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8788\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8788\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8792\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8784\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8784\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8788\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8788\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8784\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8780\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8796\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8784\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8788\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8784\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8780\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8796\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8796\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 1s 2ms/step - loss: 0.6161 - accuracy: 0.6764\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7912\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8250\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8322\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8342\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8386\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8406\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8406\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8394\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8406\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8434\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8462\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8479\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8483\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8491\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3789 - accuracy: 0.8479\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8487\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8491\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8495\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8491: 0s - loss: 0.3540 - accu\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8495\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8499\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8495\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8495\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8503\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8511\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8507\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8507\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8511\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8523\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3739 - accuracy: 0.8515\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8527\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8535\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8539\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8535\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8535\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8543\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8547\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8551\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8551\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8555\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8567\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8563\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8563\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8571\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8567\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8567\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8563\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8559\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8571\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8575\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8571\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8575\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8571\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8571\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8571\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8567\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8579\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8575\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8575\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8579\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8579\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8575\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8579\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8583\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8571\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8575\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8579\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8575\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8571\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8575\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8579\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8583\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8571\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8575\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8579\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8571\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3704 - accuracy: 0.8571\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8575\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8579\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8579\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8575\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8579\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8579\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8575\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8583\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8579\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8579\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8583\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8579\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8583\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8587\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8583\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8579\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8583\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8579\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8583\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8583\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8583\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8583\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8587\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8583\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8579\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8587\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8583\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8579\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8583\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8583\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8579\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8587\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8587\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8583\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8579\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8579\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8583\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8591\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8591\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8591\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8595\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8591\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8587\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8591\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8587\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8591\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8583\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8583\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8583\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8583\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8583\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8579\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8579\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8587\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8583\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8583\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8583\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8583\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8579\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8587\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8579\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8583\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8583\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8579\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8583\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8575\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8575\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8583\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8583\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8583\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8583\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8579\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8579\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8579\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8575: 0s - loss: 0.3638 - accuracy: \n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8575\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8579\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8583\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8579\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8579\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8579\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8583\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8579\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8579\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8579\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8579\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8575\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8579\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8583\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8579\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8579\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8579\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8575\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8575\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8579\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8579\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8575\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8579\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8571\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8579\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8579\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8575\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8575\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8575\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8575\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8575\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8579\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8571\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8575\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8579\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8571\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8575\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8571\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8567\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8567\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8571\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8567\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8575\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8571\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8579\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8575\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8579\n",
      "Epoch 1/200\n",
      "156/156 [==============================] - 1s 2ms/step - loss: 0.8412 - accuracy: 0.4275\n",
      "Epoch 2/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.5251\n",
      "Epoch 3/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.5899\n",
      "Epoch 4/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6242\n",
      "Epoch 5/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6397\n",
      "Epoch 6/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6576\n",
      "Epoch 7/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6634\n",
      "Epoch 8/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6644\n",
      "Epoch 9/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6690\n",
      "Epoch 10/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6718\n",
      "Epoch 11/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6760\n",
      "Epoch 12/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6788\n",
      "Epoch 13/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6823\n",
      "Epoch 14/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6833\n",
      "Epoch 15/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6823\n",
      "Epoch 16/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6871\n",
      "Epoch 17/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6873\n",
      "Epoch 18/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6885\n",
      "Epoch 19/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6905\n",
      "Epoch 20/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6919\n",
      "Epoch 21/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6927\n",
      "Epoch 22/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6939\n",
      "Epoch 23/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6933\n",
      "Epoch 24/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6941\n",
      "Epoch 25/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.6949\n",
      "Epoch 26/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6959\n",
      "Epoch 27/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6985\n",
      "Epoch 28/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6969\n",
      "Epoch 29/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6977\n",
      "Epoch 30/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.6993\n",
      "Epoch 31/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6979\n",
      "Epoch 32/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.6979\n",
      "Epoch 33/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7003\n",
      "Epoch 34/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6993\n",
      "Epoch 35/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7005\n",
      "Epoch 36/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7003\n",
      "Epoch 37/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7015\n",
      "Epoch 38/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7019\n",
      "Epoch 39/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7033\n",
      "Epoch 40/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7011\n",
      "Epoch 41/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7025\n",
      "Epoch 42/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7025\n",
      "Epoch 43/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7025\n",
      "Epoch 44/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7031\n",
      "Epoch 45/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7037\n",
      "Epoch 46/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7033\n",
      "Epoch 47/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7061\n",
      "Epoch 48/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7037\n",
      "Epoch 49/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7059\n",
      "Epoch 50/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7061\n",
      "Epoch 51/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7043\n",
      "Epoch 52/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7053\n",
      "Epoch 53/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7067\n",
      "Epoch 54/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7071\n",
      "Epoch 55/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7081\n",
      "Epoch 56/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7073\n",
      "Epoch 57/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7081\n",
      "Epoch 58/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7092\n",
      "Epoch 59/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7069: 0s - loss: 0.5657 - accuracy: 0.70\n",
      "Epoch 60/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7065\n",
      "Epoch 61/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7090\n",
      "Epoch 62/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7094\n",
      "Epoch 63/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7073\n",
      "Epoch 64/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7077\n",
      "Epoch 65/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7086\n",
      "Epoch 66/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7084\n",
      "Epoch 67/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7094\n",
      "Epoch 68/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7084\n",
      "Epoch 69/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7081\n",
      "Epoch 70/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7102\n",
      "Epoch 71/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7079\n",
      "Epoch 72/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7086\n",
      "Epoch 73/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7094\n",
      "Epoch 74/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7112\n",
      "Epoch 75/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7110\n",
      "Epoch 76/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7118\n",
      "Epoch 77/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7106\n",
      "Epoch 78/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7122\n",
      "Epoch 79/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7118\n",
      "Epoch 80/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7122\n",
      "Epoch 81/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7134\n",
      "Epoch 82/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7136\n",
      "Epoch 83/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7140\n",
      "Epoch 84/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7152: 0s - loss: 0.5519 - accuracy: 0.71\n",
      "Epoch 85/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7174\n",
      "Epoch 86/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7166\n",
      "Epoch 87/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7184\n",
      "Epoch 88/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7158\n",
      "Epoch 89/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7172\n",
      "Epoch 90/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7172\n",
      "Epoch 91/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7178\n",
      "Epoch 92/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7196\n",
      "Epoch 93/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7166\n",
      "Epoch 94/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7176\n",
      "Epoch 95/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7188\n",
      "Epoch 96/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7180\n",
      "Epoch 97/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7198\n",
      "Epoch 98/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7194\n",
      "Epoch 99/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7186\n",
      "Epoch 100/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7202\n",
      "Epoch 101/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7192\n",
      "Epoch 102/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7208\n",
      "Epoch 103/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7222\n",
      "Epoch 104/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7200\n",
      "Epoch 105/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7210\n",
      "Epoch 106/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7216\n",
      "Epoch 107/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7220\n",
      "Epoch 108/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7212\n",
      "Epoch 109/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7224\n",
      "Epoch 110/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7222\n",
      "Epoch 111/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7222\n",
      "Epoch 112/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7220\n",
      "Epoch 113/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7238\n",
      "Epoch 114/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7242\n",
      "Epoch 115/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7222\n",
      "Epoch 116/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7232\n",
      "Epoch 117/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7224\n",
      "Epoch 118/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7242\n",
      "Epoch 119/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7236\n",
      "Epoch 120/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7222\n",
      "Epoch 121/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7268\n",
      "Epoch 122/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7248\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7238\n",
      "Epoch 124/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7238\n",
      "Epoch 125/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7234\n",
      "Epoch 126/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7238\n",
      "Epoch 127/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7258\n",
      "Epoch 128/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7248\n",
      "Epoch 129/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7248\n",
      "Epoch 130/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7264\n",
      "Epoch 131/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7270\n",
      "Epoch 132/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7262\n",
      "Epoch 133/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7272\n",
      "Epoch 134/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7270\n",
      "Epoch 135/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7282\n",
      "Epoch 136/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7278\n",
      "Epoch 137/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7288\n",
      "Epoch 138/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7278\n",
      "Epoch 139/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7276\n",
      "Epoch 140/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7294\n",
      "Epoch 141/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7280\n",
      "Epoch 142/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7312\n",
      "Epoch 143/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7298\n",
      "Epoch 144/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7308\n",
      "Epoch 145/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7294\n",
      "Epoch 146/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7314\n",
      "Epoch 147/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7314\n",
      "Epoch 148/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7306\n",
      "Epoch 149/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7332\n",
      "Epoch 150/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7302\n",
      "Epoch 151/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7336\n",
      "Epoch 152/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7302\n",
      "Epoch 153/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7302\n",
      "Epoch 154/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7318\n",
      "Epoch 155/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7320\n",
      "Epoch 156/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7336\n",
      "Epoch 157/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7324\n",
      "Epoch 158/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7334\n",
      "Epoch 159/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7348\n",
      "Epoch 160/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7363\n",
      "Epoch 161/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7324\n",
      "Epoch 162/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7336\n",
      "Epoch 163/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7338\n",
      "Epoch 164/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7338\n",
      "Epoch 165/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7354\n",
      "Epoch 166/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7348\n",
      "Epoch 167/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7377\n",
      "Epoch 168/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7371\n",
      "Epoch 169/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7354\n",
      "Epoch 170/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7350\n",
      "Epoch 171/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7363\n",
      "Epoch 172/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7363\n",
      "Epoch 173/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7373\n",
      "Epoch 174/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7379\n",
      "Epoch 175/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7369\n",
      "Epoch 176/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7367\n",
      "Epoch 177/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7367\n",
      "Epoch 178/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7363\n",
      "Epoch 179/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7367\n",
      "Epoch 180/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7371\n",
      "Epoch 181/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7373\n",
      "Epoch 182/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7371\n",
      "Epoch 183/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7369\n",
      "Epoch 184/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7371\n",
      "Epoch 185/200\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.5249 - accuracy: 0.7403\n",
      "Epoch 186/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7369\n",
      "Epoch 187/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7401\n",
      "Epoch 188/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7373\n",
      "Epoch 189/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7399\n",
      "Epoch 190/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7403\n",
      "Epoch 191/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7415\n",
      "Epoch 192/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7403\n",
      "Epoch 193/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7397\n",
      "Epoch 194/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7395\n",
      "Epoch 195/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7423\n",
      "Epoch 196/200\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7405\n",
      "Epoch 197/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7399\n",
      "Epoch 198/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7413\n",
      "Epoch 199/200\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7393\n",
      "Epoch 200/200\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.5213 - accuracy: 0.7413: 0s - loss: 0.5213 - ac\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Neural network architecture\n",
    "\n",
    "def create_model(lr=0.1,momentum=0.8):\n",
    "    # Neural network architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,activation='tanh', input_shape=(15,)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    # Optimizer configuration\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "epochs=200\n",
    "model_search = KerasClassifier(build_fn=create_model,epochs=epochs)\n",
    "\n",
    "# Definir los parámetros del grid search\n",
    "lr = [0.1, 0.05, 0.01]\n",
    "momentum = [0.8, 0.6, 0.4]\n",
    "\n",
    "param_grid = dict(lr=lr,momentum=momentum)\n",
    "\n",
    "selection_score = make_scorer(accuracy_score) \n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=model_search, param_grid=param_grid,\n",
    "                    cv=2,return_train_score=True,\n",
    "                    scoring=selection_score)\n",
    "\n",
    "grid_result = grid.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:\n",
      "{'lr': 0.01, 'momentum': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print('Mejores parámetros:')\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 2s 28ms/step - loss: 0.6744 - accuracy: 0.5871 - val_loss: 0.6561 - val_accuracy: 0.6352\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.6675 - accuracy: 0.6036 - val_loss: 0.6486 - val_accuracy: 0.6407\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6620 - accuracy: 0.6148 - val_loss: 0.6426 - val_accuracy: 0.6489\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6574 - accuracy: 0.6190 - val_loss: 0.6377 - val_accuracy: 0.6448\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6535 - accuracy: 0.6232 - val_loss: 0.6337 - val_accuracy: 0.6434\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.6502 - accuracy: 0.6269 - val_loss: 0.6305 - val_accuracy: 0.6434\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6474 - accuracy: 0.6301 - val_loss: 0.6278 - val_accuracy: 0.6503\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.6449 - accuracy: 0.6305 - val_loss: 0.6255 - val_accuracy: 0.6530\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.6427 - accuracy: 0.6321 - val_loss: 0.6236 - val_accuracy: 0.6544\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6407 - accuracy: 0.6373 - val_loss: 0.6220 - val_accuracy: 0.6571\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6389 - accuracy: 0.6397 - val_loss: 0.6206 - val_accuracy: 0.6585\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6372 - accuracy: 0.6413 - val_loss: 0.6195 - val_accuracy: 0.6612\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6357 - accuracy: 0.6437 - val_loss: 0.6185 - val_accuracy: 0.6585\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.6463 - val_loss: 0.6177 - val_accuracy: 0.6557\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6329 - accuracy: 0.6463 - val_loss: 0.6170 - val_accuracy: 0.6516\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.6316 - accuracy: 0.6473 - val_loss: 0.6164 - val_accuracy: 0.6585\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6304 - accuracy: 0.6479 - val_loss: 0.6159 - val_accuracy: 0.6612\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.6483 - val_loss: 0.6155 - val_accuracy: 0.6639\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6501 - val_loss: 0.6151 - val_accuracy: 0.6612\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6503 - val_loss: 0.6148 - val_accuracy: 0.6612\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6497 - val_loss: 0.6145 - val_accuracy: 0.6639\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6499 - val_loss: 0.6143 - val_accuracy: 0.6639\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6505 - val_loss: 0.6142 - val_accuracy: 0.6639\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6511 - val_loss: 0.6141 - val_accuracy: 0.6639\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6527 - val_loss: 0.6140 - val_accuracy: 0.6653\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6527 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6536 - val_loss: 0.6138 - val_accuracy: 0.6653\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6550 - val_loss: 0.6138 - val_accuracy: 0.6653\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6552 - val_loss: 0.6138 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6574 - val_loss: 0.6137 - val_accuracy: 0.6680\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.6586 - val_loss: 0.6137 - val_accuracy: 0.6653\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6594 - val_loss: 0.6137 - val_accuracy: 0.6653\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6608 - val_loss: 0.6137 - val_accuracy: 0.6639\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6600 - val_loss: 0.6137 - val_accuracy: 0.6639\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.6616 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6614 - val_loss: 0.6137 - val_accuracy: 0.6653\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6608 - val_loss: 0.6138 - val_accuracy: 0.6612\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6624 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6636 - val_loss: 0.6139 - val_accuracy: 0.6639\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6644 - val_loss: 0.6140 - val_accuracy: 0.6639\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6646 - val_loss: 0.6140 - val_accuracy: 0.6612\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6640 - val_loss: 0.6140 - val_accuracy: 0.6598\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6648 - val_loss: 0.6140 - val_accuracy: 0.6571\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6658 - val_loss: 0.6141 - val_accuracy: 0.6557\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6664 - val_loss: 0.6141 - val_accuracy: 0.6516\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6668 - val_loss: 0.6142 - val_accuracy: 0.6489\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6670 - val_loss: 0.6143 - val_accuracy: 0.6489\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6073 - accuracy: 0.6662 - val_loss: 0.6143 - val_accuracy: 0.6489\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6688 - val_loss: 0.6144 - val_accuracy: 0.6489\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6704 - val_loss: 0.6144 - val_accuracy: 0.6503\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6704 - val_loss: 0.6144 - val_accuracy: 0.6503\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.6700 - val_loss: 0.6144 - val_accuracy: 0.6544\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.6712 - val_loss: 0.6145 - val_accuracy: 0.6544\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6714 - val_loss: 0.6146 - val_accuracy: 0.6571\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6728 - val_loss: 0.6146 - val_accuracy: 0.6571\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6742 - val_loss: 0.6146 - val_accuracy: 0.6557\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6033 - accuracy: 0.6750 - val_loss: 0.6147 - val_accuracy: 0.6557\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6029 - accuracy: 0.6764 - val_loss: 0.6149 - val_accuracy: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6762 - val_loss: 0.6149 - val_accuracy: 0.6544\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6786 - val_loss: 0.6150 - val_accuracy: 0.6544\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.6796 - val_loss: 0.6150 - val_accuracy: 0.6530\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.6015 - accuracy: 0.6792 - val_loss: 0.6150 - val_accuracy: 0.6530\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.6012 - accuracy: 0.6796 - val_loss: 0.6151 - val_accuracy: 0.6530\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.6008 - accuracy: 0.6796 - val_loss: 0.6151 - val_accuracy: 0.6516\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.6788 - val_loss: 0.6152 - val_accuracy: 0.6530\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6002 - accuracy: 0.6788 - val_loss: 0.6152 - val_accuracy: 0.6530\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5999 - accuracy: 0.6800 - val_loss: 0.6153 - val_accuracy: 0.6530\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5996 - accuracy: 0.6788 - val_loss: 0.6153 - val_accuracy: 0.6530\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5993 - accuracy: 0.6804 - val_loss: 0.6154 - val_accuracy: 0.6530\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5990 - accuracy: 0.6804 - val_loss: 0.6155 - val_accuracy: 0.6530\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5987 - accuracy: 0.6788 - val_loss: 0.6155 - val_accuracy: 0.6516\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5985 - accuracy: 0.6782 - val_loss: 0.6157 - val_accuracy: 0.6544\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.6792 - val_loss: 0.6157 - val_accuracy: 0.6530\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5980 - accuracy: 0.6804 - val_loss: 0.6158 - val_accuracy: 0.6530\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5977 - accuracy: 0.6802 - val_loss: 0.6158 - val_accuracy: 0.6544\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5974 - accuracy: 0.6807 - val_loss: 0.6159 - val_accuracy: 0.6544\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5972 - accuracy: 0.6817 - val_loss: 0.6159 - val_accuracy: 0.6557\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5970 - accuracy: 0.6819 - val_loss: 0.6160 - val_accuracy: 0.6544\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.5967 - accuracy: 0.6821 - val_loss: 0.6161 - val_accuracy: 0.6544\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5965 - accuracy: 0.6831 - val_loss: 0.6162 - val_accuracy: 0.6557\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.6827 - val_loss: 0.6163 - val_accuracy: 0.6571\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5961 - accuracy: 0.6827 - val_loss: 0.6164 - val_accuracy: 0.6598\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5958 - accuracy: 0.6831 - val_loss: 0.6165 - val_accuracy: 0.6557\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5956 - accuracy: 0.6841 - val_loss: 0.6165 - val_accuracy: 0.6571\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5954 - accuracy: 0.6843 - val_loss: 0.6165 - val_accuracy: 0.6571\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5952 - accuracy: 0.6843 - val_loss: 0.6165 - val_accuracy: 0.6571\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5950 - accuracy: 0.6837 - val_loss: 0.6166 - val_accuracy: 0.6585\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5948 - accuracy: 0.6845 - val_loss: 0.6166 - val_accuracy: 0.6598\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5947 - accuracy: 0.6845 - val_loss: 0.6166 - val_accuracy: 0.6598\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.6843 - val_loss: 0.6167 - val_accuracy: 0.6626\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.5943 - accuracy: 0.6837 - val_loss: 0.6167 - val_accuracy: 0.6626\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.6845 - val_loss: 0.6167 - val_accuracy: 0.6612\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.6857 - val_loss: 0.6167 - val_accuracy: 0.6612\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6857 - val_loss: 0.6167 - val_accuracy: 0.6612\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.6855 - val_loss: 0.6168 - val_accuracy: 0.6612\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6853 - val_loss: 0.6168 - val_accuracy: 0.6626\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5933 - accuracy: 0.6863 - val_loss: 0.6168 - val_accuracy: 0.6626\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.6865 - val_loss: 0.6169 - val_accuracy: 0.6626\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.5930 - accuracy: 0.6867 - val_loss: 0.6169 - val_accuracy: 0.6612\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5928 - accuracy: 0.6869 - val_loss: 0.6169 - val_accuracy: 0.6612\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5927 - accuracy: 0.6859 - val_loss: 0.6169 - val_accuracy: 0.6598\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5925 - accuracy: 0.6865 - val_loss: 0.6169 - val_accuracy: 0.6598\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.6871 - val_loss: 0.6170 - val_accuracy: 0.6598\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5923 - accuracy: 0.6871 - val_loss: 0.6170 - val_accuracy: 0.6598\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.6875 - val_loss: 0.6170 - val_accuracy: 0.6598\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.6875 - val_loss: 0.6171 - val_accuracy: 0.6598\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5918 - accuracy: 0.6869 - val_loss: 0.6170 - val_accuracy: 0.6598\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6869 - val_loss: 0.6171 - val_accuracy: 0.6585\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.6867 - val_loss: 0.6171 - val_accuracy: 0.6585\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5914 - accuracy: 0.6863 - val_loss: 0.6171 - val_accuracy: 0.6585\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.6869 - val_loss: 0.6170 - val_accuracy: 0.6571\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5912 - accuracy: 0.6865 - val_loss: 0.6170 - val_accuracy: 0.6585\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.5911 - accuracy: 0.6875 - val_loss: 0.6170 - val_accuracy: 0.6557\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.5910 - accuracy: 0.6873 - val_loss: 0.6170 - val_accuracy: 0.6571\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5908 - accuracy: 0.6875 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5907 - accuracy: 0.6867 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5906 - accuracy: 0.6877 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5905 - accuracy: 0.6867 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.6859 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5902 - accuracy: 0.6873 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5901 - accuracy: 0.6865 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5900 - accuracy: 0.6855 - val_loss: 0.6169 - val_accuracy: 0.6571\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5899 - accuracy: 0.6869 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.6863 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5897 - accuracy: 0.6865 - val_loss: 0.6169 - val_accuracy: 0.6557\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.5896 - accuracy: 0.6867 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6867 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.6867 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5892 - accuracy: 0.6861 - val_loss: 0.6168 - val_accuracy: 0.6571\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.6861 - val_loss: 0.6167 - val_accuracy: 0.6571\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.5890 - accuracy: 0.6857 - val_loss: 0.6167 - val_accuracy: 0.6571\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5889 - accuracy: 0.6863 - val_loss: 0.6166 - val_accuracy: 0.6571\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6863 - val_loss: 0.6166 - val_accuracy: 0.6571\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5887 - accuracy: 0.6859 - val_loss: 0.6165 - val_accuracy: 0.6571\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.5886 - accuracy: 0.6863 - val_loss: 0.6165 - val_accuracy: 0.6585\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.6857 - val_loss: 0.6165 - val_accuracy: 0.6585\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.6859 - val_loss: 0.6164 - val_accuracy: 0.6585\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5883 - accuracy: 0.6861 - val_loss: 0.6165 - val_accuracy: 0.6585\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.6861 - val_loss: 0.6164 - val_accuracy: 0.6598\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5881 - accuracy: 0.6865 - val_loss: 0.6164 - val_accuracy: 0.6598\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5881 - accuracy: 0.6867 - val_loss: 0.6163 - val_accuracy: 0.6598\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5879 - accuracy: 0.6863 - val_loss: 0.6163 - val_accuracy: 0.6598\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.6865 - val_loss: 0.6161 - val_accuracy: 0.6598\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.6877 - val_loss: 0.6161 - val_accuracy: 0.6598\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.6871 - val_loss: 0.6161 - val_accuracy: 0.6598\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.5876 - accuracy: 0.6875 - val_loss: 0.6161 - val_accuracy: 0.6598\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.6875 - val_loss: 0.6161 - val_accuracy: 0.6598\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.6869 - val_loss: 0.6160 - val_accuracy: 0.6598\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6873 - val_loss: 0.6160 - val_accuracy: 0.6598\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5872 - accuracy: 0.6883 - val_loss: 0.6159 - val_accuracy: 0.6598\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5871 - accuracy: 0.6871 - val_loss: 0.6158 - val_accuracy: 0.6598\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5870 - accuracy: 0.6877 - val_loss: 0.6158 - val_accuracy: 0.6598\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5869 - accuracy: 0.6879 - val_loss: 0.6158 - val_accuracy: 0.6598\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.6875 - val_loss: 0.6158 - val_accuracy: 0.6598\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5868 - accuracy: 0.6879 - val_loss: 0.6157 - val_accuracy: 0.6598\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5867 - accuracy: 0.6879 - val_loss: 0.6156 - val_accuracy: 0.6598\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.6883 - val_loss: 0.6156 - val_accuracy: 0.6598\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5865 - accuracy: 0.6881 - val_loss: 0.6156 - val_accuracy: 0.6598\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.6879 - val_loss: 0.6156 - val_accuracy: 0.6598\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5863 - accuracy: 0.6887 - val_loss: 0.6155 - val_accuracy: 0.6598\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.6893 - val_loss: 0.6155 - val_accuracy: 0.6598\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5862 - accuracy: 0.6889 - val_loss: 0.6154 - val_accuracy: 0.6598\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.6895 - val_loss: 0.6154 - val_accuracy: 0.6598\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.6893 - val_loss: 0.6153 - val_accuracy: 0.6598\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.5859 - accuracy: 0.6885 - val_loss: 0.6152 - val_accuracy: 0.6598\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.6885 - val_loss: 0.6153 - val_accuracy: 0.6598\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.6889 - val_loss: 0.6152 - val_accuracy: 0.6598\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.6893 - val_loss: 0.6151 - val_accuracy: 0.6598\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5856 - accuracy: 0.6891 - val_loss: 0.6151 - val_accuracy: 0.6598\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5855 - accuracy: 0.6887 - val_loss: 0.6150 - val_accuracy: 0.6598\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.6899 - val_loss: 0.6149 - val_accuracy: 0.6598\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.6885 - val_loss: 0.6148 - val_accuracy: 0.6598\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5853 - accuracy: 0.6901 - val_loss: 0.6148 - val_accuracy: 0.6598\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5852 - accuracy: 0.6895 - val_loss: 0.6148 - val_accuracy: 0.6598\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.6895 - val_loss: 0.6147 - val_accuracy: 0.6598\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.6895 - val_loss: 0.6147 - val_accuracy: 0.6598\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.6893 - val_loss: 0.6146 - val_accuracy: 0.6598\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5848 - accuracy: 0.6897 - val_loss: 0.6146 - val_accuracy: 0.6598\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.6901 - val_loss: 0.6146 - val_accuracy: 0.6612\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5847 - accuracy: 0.6899 - val_loss: 0.6144 - val_accuracy: 0.6612\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5846 - accuracy: 0.6903 - val_loss: 0.6144 - val_accuracy: 0.6612\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5845 - accuracy: 0.6901 - val_loss: 0.6144 - val_accuracy: 0.6612\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.6903 - val_loss: 0.6143 - val_accuracy: 0.6612\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5844 - accuracy: 0.6907 - val_loss: 0.6142 - val_accuracy: 0.6612\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.6903 - val_loss: 0.6142 - val_accuracy: 0.6612\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.6903 - val_loss: 0.6142 - val_accuracy: 0.6626\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.6901 - val_loss: 0.6141 - val_accuracy: 0.6626\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.6911 - val_loss: 0.6140 - val_accuracy: 0.6626\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.6901 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.6903 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.6907 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6911 - val_loss: 0.6138 - val_accuracy: 0.6626\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.6913 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.6913 - val_loss: 0.6139 - val_accuracy: 0.6626\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6913 - val_loss: 0.6138 - val_accuracy: 0.6626\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6915 - val_loss: 0.6138 - val_accuracy: 0.6626\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6911 - val_loss: 0.6138 - val_accuracy: 0.6626\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6919 - val_loss: 0.6137 - val_accuracy: 0.6626\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6915 - val_loss: 0.6137 - val_accuracy: 0.6626\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6915 - val_loss: 0.6136 - val_accuracy: 0.6626\n"
     ]
    }
   ],
   "source": [
    "#Diseñar modelo con métricas optimizadas\n",
    "epochs = 200\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate/epochs\n",
    "momentum = 0.4\n",
    "\n",
    "# Red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(10,activation='tanh', input_shape=(15,)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Optimizer configuration\n",
    "#gradiente descendente\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Ajustar modelo\n",
    "model_history = model.fit(X_train_res, y_train_res,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=200,\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\t Precision\t Recall\n",
      " 0.663\t 0.802\t 0.663\n"
     ]
    }
   ],
   "source": [
    "#Performance\n",
    "yhat_NN = model.predict(X_test)\n",
    "accu_NN = accuracy_score(y_test,(model.predict(X_test)>0.5).astype(\"int32\"))\n",
    "prec_NN = precision_score(y_test,(model.predict(X_test)>0.5).astype(\"int32\"),average='weighted')\n",
    "reca_NN = recall_score(y_test,(model.predict(X_test)>0.5).astype(\"int32\"),average='weighted')\n",
    "print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_NN,prec_NN,reca_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.681051</td>\n",
       "      <td>0.676873</td>\n",
       "      <td>0.692979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.662568</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.662568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.771858</td>\n",
       "      <td>0.784292</td>\n",
       "      <td>0.771858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.785519</td>\n",
       "      <td>0.753930</td>\n",
       "      <td>0.785519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.662568</td>\n",
       "      <td>0.801817</td>\n",
       "      <td>0.662568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  Accuracy  Precision    Recall\n",
       "0        LR  0.681051   0.676873  0.692979\n",
       "1       SVC  0.662568   0.760000  0.662568\n",
       "2        RF  0.771858   0.784292  0.771858\n",
       "3   XGBoost  0.785519   0.753930  0.785519\n",
       "4        NN  0.662568   0.801817  0.662568"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_compar_cross = {'Modelo': ['LR', 'SVC','RF',' XGBoost', 'NN'], 'Accuracy': [np.mean(log_acc),accu_svc,accu_rf,accu_xgb,accu_NN], 'Precision': [np.mean(log_prec),prec_svc,prec_rf,prec_xgb,prec_NN], 'Recall': [np.mean(log_rec) ,reca_svc,reca_rf ,reca_xgb,reca_NN]}\n",
    "data_compar_cross = pd.DataFrame(data_compar_cross)\n",
    "data_compar_cross"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
